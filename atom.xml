<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Gina</title>
  
  <subtitle>Unknown data analyst</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-01-08T05:58:58.680Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>ginazhu</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>About Me</title>
    <link href="http://yoursite.com/2020/about/"/>
    <id>http://yoursite.com/2020/about/</id>
    <published>2020-01-08T04:37:04.000Z</published>
    <updated>2020-01-08T05:58:58.680Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>A Data Analyst, live in ShangHai, China.</p></blockquote><p>GitHub: xxx<br />QQ: xxx<br />微信: xxx</p><a id="more"></a>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;A Data Analyst, live in ShangHai, China.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;GitHub: xxx&lt;br /&gt;
QQ: xxx&lt;br /&gt;
微信: xxx&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="个人" scheme="http://yoursite.com/tags/%E4%B8%AA%E4%BA%BA/"/>
    
  </entry>
  
  <entry>
    <title>ceph</title>
    <link href="http://yoursite.com/2020/ck54wfd9r0002y76baebbf0ly/"/>
    <id>http://yoursite.com/2020/ck54wfd9r0002y76baebbf0ly/</id>
    <published>2020-01-07T01:56:33.000Z</published>
    <updated>2020-01-07T02:04:36.921Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Ceph部署文档</strong></p><p>编辑hosts文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/hosts</span><br><span class="line">192.168.0.41 ceph-node1 ceph-mon1</span><br><span class="line">192.168.0.42 ceph-node2 ceph-mon2</span><br><span class="line">192.168.0.44 ceph-node3 ceph-mon3</span><br><span class="line">192.168.0.45 ceph-node4 ceph-mgr1</span><br><span class="line">192.168.0.46 ceph-node5 ceph-mgr2 ceph-rgw</span><br></pre></td></tr></table></figure><p>设置hostname</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hostnamectl <span class="built_in">set</span>-hostname ceph-node1</span><br><span class="line">hostnamectl <span class="built_in">set</span>-hostname ceph-node2</span><br><span class="line">hostnamectl <span class="built_in">set</span>-hostname ceph-node3</span><br></pre></td></tr></table></figure><p>生成ssh-key</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#ssh-keygen</span></span><br><span class="line">对需要访问的机器进行认证</span><br><span class="line">ssh-copy-id root@ceph-node1</span><br><span class="line">ssh-copy-id root@ceph-node2    //拷贝到所有节点</span><br><span class="line">ssh-copy-id root@ceph-node3</span><br></pre></td></tr></table></figure><p>在ceph-deploy节点执行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##创建集群</span></span><br><span class="line"><span class="comment">#创建monitor节点（依据需要的mon数量来对节点执行，必须是奇数，最少是一个）</span></span><br><span class="line"><span class="comment">#例如:ceph-deploy new &#123;initial-monitor-node(s)&#125;</span></span><br><span class="line">mkdir my-cluster</span><br><span class="line"><span class="built_in">cd</span> my-cluster</span><br><span class="line"> ceph-deploy new ceph-node1 ceph-node2 ceph-node3</span><br></pre></td></tr></table></figure><p>安装后生成三个文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">编辑ceph.conf   注（public network是和mon一样的公共网络）</span><br><span class="line">[global]</span><br><span class="line">fsid = 74c047d3-2d2f-4fd9-9db1-30394d4e6f3a</span><br><span class="line">mon_initial_members = ceph-node1, ceph-node2, ceph-node3</span><br><span class="line">mon_host = 192.168.0.41,192.168.0.42,192.168.0.44</span><br><span class="line">auth_cluster_required = cephx</span><br><span class="line">auth_service_required = cephx</span><br><span class="line">auth_client_required = cephx</span><br><span class="line"></span><br><span class="line">添加网络</span><br><span class="line">public network = 10.30.0.0/24</span><br><span class="line">cluster network = 10.31.0.0/24</span><br></pre></td></tr></table></figure><p>这里用下面命令替换了官方的命令（ceph-deploy install ceph-node1 ceph-node2 ceph-node3）,由于用官方命令会把阿里云的源顶掉所以需要用下面的命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y ceph ceph-radosgw        <span class="comment">#在每个节点执行  ，rgw看需求安装</span></span><br></pre></td></tr></table></figure><p>初始化monitor(s)，并收集所有秘钥</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">只在node1上面安装的，需要在my-clust目录执行</span><br><span class="line">ceph-deploy mon create-initial</span><br><span class="line">复制配置信息到各个节点</span><br><span class="line">ceph-deploy admin ceph-node1 ceph-node2 ceph-node3</span><br></pre></td></tr></table></figure><p>安装Mgr</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#ceph-deploy mgr create ceph-node4 ceph-node5</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#ceph mgr module enable dashboard</span></span><br><span class="line"></span><br><span class="line">查看dashboard端口7000</span><br><span class="line"></span><br><span class="line">netstat -tunlp|grep 7000</span><br></pre></td></tr></table></figure><p>使用zap选项删除所有osd节点上的分区，磁盘较多。重复执行即可</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ceph-deploy disk zap ceph-node1 /dev/sdb</span><br><span class="line"></span><br><span class="line">ceph-deploy disk zap ceph-node2 /dev/sdb</span><br><span class="line"></span><br><span class="line">ceph-deploy disk zap ceph-node3/dev/sdb</span><br><span class="line"></span><br><span class="line">ceph-deploy disk zap ceph-node4 /dev/sdb</span><br><span class="line"></span><br><span class="line">ceph-deploy disk zap ceph-node5 /dev/sdb</span><br></pre></td></tr></table></figure><p>启动创建osd，如果磁盘比较多，安装规划磁盘名称，重复执行即可</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ceph-deploy osd create --data  /dev/sdb ceph-node1</span><br><span class="line">ceph-deploy osd create --data  /dev/sdb ceph-node2</span><br><span class="line">ceph-deploy osd create --data  /dev/sdb ceph-node3</span><br><span class="line">ceph-deploy osd create --data  /dev/sdb ceph-node4</span><br><span class="line">ceph-deploy osd create --data  /dev/sdb ceph-node5</span><br></pre></td></tr></table></figure><p>查看集群状态</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph-node1 my-cluster]<span class="comment"># ceph -s </span></span><br><span class="line">  cluster:</span><br><span class="line">    id:     74c047d3-2d2f-4fd9-9db1-30394d4e6f3a</span><br><span class="line">    health: HEALTH_OK</span><br><span class="line"></span><br><span class="line">  services:</span><br><span class="line">    mon: 3 daemons, quorum ceph-node1,ceph-node2,ceph-node3</span><br><span class="line">    mgr: ceph-node4(active), standbys: ceph-node5</span><br><span class="line">    osd: 18 osds: 18 up, 18 <span class="keyword">in</span></span><br><span class="line"></span><br><span class="line">  data:</span><br><span class="line">    pools:   1 pools, 512 pgs</span><br><span class="line">    objects: 0 objects, 0B</span><br><span class="line">    usage:   18.2GiB used, 28.5TiB / 28.6TiB avail</span><br><span class="line">    pgs:     512 active+clean</span><br></pre></td></tr></table></figure><p>对象存储部署，这里部署到了node5节点</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">yum install -y ceph-radosgw         （在node5节点执行）</span><br><span class="line"></span><br><span class="line">部署rgw   需要切换到my-cluster目录执行  （在node1节点执行）</span><br><span class="line"></span><br><span class="line">ceph-deploy rgw create ceph-node5</span><br><span class="line"></span><br><span class="line">完成后会启动7480端口</span><br><span class="line"></span><br><span class="line">[root@ceph-node5 ~]<span class="comment"># netstat -tnlp |grep 7480</span></span><br><span class="line">tcp    0      0 0.0.0.0:7480        0.0.0.0:*               LISTEN      41303/radosgw</span><br></pre></td></tr></table></figure><p>创建pool池命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">cat create_pool.sh </span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">PG_NUM=30</span><br><span class="line">PGP_NUM=30</span><br><span class="line">SIZE=3</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> `cat /home/my-cluster/pool`</span><br><span class="line">        <span class="keyword">do</span></span><br><span class="line">        ceph osd pool create <span class="variable">$i</span> <span class="variable">$PG_NUM</span></span><br><span class="line">        ceph osd pool <span class="built_in">set</span> <span class="variable">$i</span> size <span class="variable">$SIZE</span></span><br><span class="line">        <span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> `cat /home/my-cluster/pool`</span><br><span class="line">        <span class="keyword">do</span></span><br><span class="line">        ceph osd pool <span class="built_in">set</span> <span class="variable">$i</span> pgp_num <span class="variable">$PGP_NUM</span></span><br><span class="line">        <span class="keyword">done</span></span><br></pre></td></tr></table></figure><p>删除pool池命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">删除pool池命令</span><br><span class="line">cat delete_pool.sh</span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">PG_NUM=30</span><br><span class="line">PGP_NUM=30</span><br><span class="line">SIZE=3</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> `cat /home/my-cluster/pool`</span><br><span class="line">        <span class="keyword">do</span></span><br><span class="line">        ceph osd pool delete <span class="variable">$i</span> <span class="variable">$i</span> --yes-i-really-really-mean-it</span><br><span class="line">        <span class="keyword">done</span></span><br></pre></td></tr></table></figure><p>单个删除pool命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ceph osd  pool delete rbd rbd --yes-i-really-really-mean-it</span><br><span class="line"></span><br><span class="line">查看刚才创建的秘钥是不是能访问ceph集群，在node5上查看</span><br><span class="line"></span><br><span class="line">cat  /var/lib/ceph/radosgw/ceph-rgw.ceph-node5/keyring </span><br><span class="line">[client.rgw.ceph-node5]</span><br><span class="line">key = AQDFfFNd0Rj/MxAAd5MUngvmUHdW72eFNE7jGQ==</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;Ceph部署文档&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;编辑hosts文件&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/sp
      
    
    </summary>
    
    
    
      <category term="技术" scheme="http://yoursite.com/tags/%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title>红帽pupbline脚本</title>
    <link href="http://yoursite.com/2020/ck54wfd9w0004y76bh7qq91d9/"/>
    <id>http://yoursite.com/2020/ck54wfd9w0004y76bh7qq91d9/</id>
    <published>2020-01-07T01:56:33.000Z</published>
    <updated>2020-01-07T02:04:50.111Z</updated>
    
    <content type="html"><![CDATA[<p><strong>红帽pipeline脚本</strong><br />脚本如下格式</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">#!groovy</span><br><span class="line">node('maven') &#123;</span><br><span class="line">  def mvnCmd = "mvn -s ./nexus_openshift_settings.xml"</span><br><span class="line"></span><br><span class="line">  stage('Checkout Source') &#123;</span><br><span class="line">    git 'http://gogs-cicd-demo-tools.apps.ocp-test.com/gogs/pt01.git'</span><br><span class="line">    sh "ls -l"</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  def groupId    = getGroupIdFromPom("pom.xml")</span><br><span class="line">  def artifactId = getArtifactIdFromPom("pom.xml")</span><br><span class="line">  def version    = getVersionFromPom("pom.xml")</span><br><span class="line">  stage('Build war') &#123;</span><br><span class="line">    sh "$&#123;mvnCmd&#125; clean package -DskipTests"</span><br><span class="line">  &#125;</span><br><span class="line">  stage('Unit Tests') &#123;</span><br><span class="line">    echo "Unit Tests"</span><br><span class="line">    sh "$&#123;mvnCmd&#125; test"</span><br><span class="line">  &#125;</span><br><span class="line">  stage('Code Analysis') &#123;</span><br><span class="line">    echo "Code Analysis"</span><br><span class="line">    sh "echo $&#123;JOB_BASE_NAME&#125;"</span><br><span class="line">    sh "$&#123;mvnCmd&#125; sonar:sonar -Dsonar.host.url=http://sonarqube.cicd-demo-tools.svc:9000/ -Dsonar.projectName=$&#123;JOB_BASE_NAME&#125;"</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  stage('Publish to Nexus') &#123;</span><br><span class="line">    echo "Publish to Nexus"</span><br><span class="line">    sh "$&#123;mvnCmd&#125; deploy -DskipTests=true -DaltDeploymentRepository=nexus::default::http://nexus3-cicd-demo-tools.apps.ocp-test.com/repository/maven-releases/"</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  stage('Build OpenShift Image') &#123;</span><br><span class="line">    sh "cp ./target/pipeline-test-1.0.war ./ROOT.war"</span><br><span class="line">    sh "oc start-build pt --follow --from-file=./ROOT.war -n pt01-dev"</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  stage('Deploy to Dev') &#123;</span><br><span class="line">    sh "oc patch dc pt --patch '&#123;\"spec\": &#123; \"triggers\": [ &#123; \"type\": \"ImageChange\", \"imageChangeParams\": &#123; \"containerNames\": [ \"pt\" ], \"from\": &#123; \"kind\": \"ImageStreamTag\", \"namespace\": \"pt01-dev\", \"name\": \"pt:latest\"&#125;&#125;&#125;]&#125;&#125;' -n pt01-dev"</span><br><span class="line">    openshiftDeploy depCfg: 'pt', namespace: 'pt01-dev', verbose: 'false', waitTime: '', waitUnit: 'sec'</span><br><span class="line">    openshiftVerifyDeployment depCfg: 'pt', namespace: 'pt01-dev', replicaCount: '1', verbose: 'false', verifyReplicaCount: 'false', waitTime: '', waitUnit: 'sec'</span><br><span class="line">    openshiftVerifyService namespace: 'pt01-dev', svcName: 'pt', verbose: 'false'</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  stage('是否发布生产？') &#123;</span><br><span class="line">    input "是否发布生产?"</span><br><span class="line">    echo "OK!"</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  stage('Deploy to Pro') &#123;</span><br><span class="line">    sh "oc patch dc pt --patch '&#123;\"spec\": &#123; \"triggers\": [ &#123; \"type\": \"ImageChange\", \"imageChangeParams\": &#123; \"containerNames\": [ \"pt\" ], \"from\": &#123; \"kind\": \"ImageStreamTag\", \"namespace\": \"pt01-dev\", \"name\": \"pt:latest\"&#125;&#125;&#125;]&#125;&#125;' -n pt01-pro"</span><br><span class="line">    openshiftDeploy depCfg: 'pt', namespace: 'pt01-pro', verbose: 'false', waitTime: '', waitUnit: 'sec'</span><br><span class="line">    openshiftVerifyDeployment depCfg: 'pt', namespace: 'pt01-pro', replicaCount: '1', verbose: 'false', verifyReplicaCount: 'true', waitTime: '', waitUnit: 'sec'</span><br><span class="line">    openshiftVerifyService namespace: 'pt01-pro', svcName: 'pt', verbose: 'false'</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">def getVersionFromPom(pom) &#123;</span><br><span class="line">  def matcher = readFile(pom) =~ '&lt;version&gt;(.+)&lt;/version&gt;'</span><br><span class="line">  matcher ? matcher[0][1] : null</span><br><span class="line">&#125;</span><br><span class="line">def getGroupIdFromPom(pom) &#123;</span><br><span class="line">  def matcher = readFile(pom) =~ '&lt;groupId&gt;(.+)&lt;/groupId&gt;'</span><br><span class="line">  matcher ? matcher[0][1] : null</span><br><span class="line">&#125;</span><br><span class="line">def getArtifactIdFromPom(pom) &#123;</span><br><span class="line">  def matcher = readFile(pom) =~ '&lt;artifactId&gt;(.+)&lt;/artifactId&gt;'</span><br><span class="line">  matcher ? matcher[0][1] : null</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;红帽pipeline脚本&lt;/strong&gt;&lt;br /&gt;
脚本如下格式&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;b
      
    
    </summary>
    
    
    
      <category term="脚本" scheme="http://yoursite.com/tags/%E8%84%9A%E6%9C%AC/"/>
    
  </entry>
  
</feed>
